从数据来源分类，可以将存储层数据分为两类，一类是ApusData的内建存储层写入到COS的数据，另一部分是ApusData访问用户保存在COS上的外部数据。对于内建存储层，用户通过http或者tcp连接，将数据写入到ApusData，ApusData再将其转为内置存储层的数据存储结构，写入到COS，同时将索引文件也写入到COS。对于用户直接写入到COS上的只读数据，ApusData会为其创建索引文件，保存到COS中，用以加速查询。

ApusData 的主要应用场景是执行大量需要进行读优化的 ad-hoc 查询，对于内建存储部分，我们需要设计专门的二进制数据存储格式来加速查询，需要设计专门的目录组织结构来决定一张表如何通过目录与文件组织在一起，我们将这两方面的内容合并称为 Apus Storage Format。

日志分析场景下，查询通常只会查询多个列中的几个列，如果采用行存势必会引入不必要的IO开销，因此采用列式存储（column-oriented storage）是非常直观的选择，这也是现在比较流行的云数据仓库 SnowFlake 以及 DataBricks 的做法。
选定列式存储后，需要选择列存二进制数据的存储形式。列式存储有两种存储形式，一种是纯列存（Pure Column Storage），每个列都保存在一个单独的数据文件内，还有一种是比较紧凑的格式（Hybrid Column Storage），列数据都保存在同一个文件内，同一个列的数据保存在文件内的相邻的位置。已经有学术论文证明了，对于读取性能而言，纯列存与混合列存没有本质区别，而且在COS上使用纯列存会增加对象数量，对COS来说会有元数据管理压力，所以我们在存储层决定采用紧凑的Hybrid Column Storage Format。

---

**这一部分是详细对比 PAX，Parquet，Clickhouse 的 Compact Part 以及 Wide Part 格式，也许在概要设计中可以删除。**
SnowFlake 的数据存储采用 PAX 格式，DataBricks 采用的是 Apache Parquet，Clickhouse 
对比 Apache ORC，Apache Parquet，以及 Clickhouse Compact Part。

SnowFlake 采用的是 PAX 文件格式，这是一种混合列式文件存储格式。每个表的都包含一个 header，header 中记录了每个列在文件中的 offset，以及一些其他元数据。因为 S3 允许 GET 方法获取文件的部分内容，所以查询只需要将 file header 下载下来，然后去访问需要访问的列的内容。

Compact Part 优势：
1. 数据类型更加丰富
2. 对Clickhouse的一些内置数据类型支持的更好（Lowcardinality)

结论是：
不考虑工程实现，直接使用 Apache Parquet 格式；考虑工程实现难度，直接采用 Clickhouse 的 Compact part

---

对于每张表，我们会为其创建一个以其UUID为名字的本地文件系统文件夹，在每个文件夹内部包含二级目录，不同的 Partition 将会有各自的目录，第三级目录则是 Part 目录。
```
mytable-uuid/
├── date=2020-01-01/
|   ├── PartA
│   |   ├── checksums.txt
│   |   ├── columns.txt
│   |   ├── count.txt
│   |   ├── data.bin
│   |   ├── data.mrk3
│   |   ├── default_compression_codec.txt
│   |   ├── primary.idx
│   |   └── uuid.txt
...
```
Part 是我们进行数据管理的单位，每次用户的 insert 操作都会生成一个 part，后台的异步线程将会不定期合并小的 part，生成大的 part，我们称这个过程为 merge part。Merge part 可以减少文件数量，相比查询多个小文件，查询单个大文件可以显著提高查询效率，减少对象存储上的对象数量。由于 merge part 过程是在 Apus Engine 内完成的，如果没有本地 part 缓存，会导致整个 merge 过程产生大量的 COS 对象访问，因此我们需要引入 Volatile Part，其目的是利用本地的磁盘，将一部分 part 保存在本地，只将第一次写入的 part 以及足够大的 part 上传至 COS，这样可以最大限度减少 merge 过程中 COS 上的读写放大。